version: '3'

# Must declare a named volume which is mapped to Hanelly container directory
# this is because the container directory is not empty and we don't want the host directory to overwrite it.
# named volumes must be removed manually or they will stick around after 'docker stack rm'
volumes:
  hanelly-data:
  # need more here for JVM working dirs for all containers that have them...
  # but need to also understand named volume cleanup very well before we go creating tons of named volumes that stick around

services:
  apache-shib:
    image: nakisa/apache:${NAK_APACSHIB_IMG_TAG}
    depends_on:
      - hanelly
    volumes:
      - ./apache-ssl:/etc/apache2/ssl
      - ./apache-conf:/etc/apache2/sites-enabled
      - ./apache-logs:/var/log/apache2
      - ./apache-shib:/usr/local/shibboleth
    ports:
      - "80:80"
      - "443:443"

  hanelly:
    image: nakisa/hanelly:${NAK_HANELLY_IMG_TAG}
    depends_on:
      - hanelly-db
      - redis
      - elasticsearch
    volumes:
      - ./bnr-data:/nakisa/backup
      - ./agent:/usr/local/tomcat/agent/
      - ./idocs-data:/nakisa/idocs
      # the following volume is mapped to a named volume because it contains subdirectories and data which we don't want to overwrite
      - hanelly-data:/usr/local/tomcat/webapps/hanelly
    environment:
      JAVA_OPTS: "-Dfile.encoding='UTF-8'"
      CATALINA_OPTS: "-javaagent:/usr/local/tomcat/agent/jmx_prometheus_javaagent-0.8.jar=4000:/usr/local/tomcat/agent/tomcat.yml -Ddynamic.embedded=false -Ddynamic.host=elasticsearch -Ddynamic.cluster=elasticsearch -Dcluster.standalone=false -Dcluster.discovery.file=WEB-INF/tcp.xml -Djgroups.bind_addr=hanelly -Djava.net.preferIPv4Stack=true -Dnak.authentication.token=${NAK_AUTH_TOKEN} -Dnak.volume.path.idoc=/nakisa/idocs -Dnak.volume.path.backup=/nakisa/backup -Dnak.queue.url=http://taskmanager:10000/queue-manager -Dnak.backup.app.url=http://backupmanager:10001/backup-manager -Dnak.idoc.app.url=http://idoclistener:10002/idoc-listener -Dfile.encoding='UTF-8' ${NAK_HANELLY_MEM_ALLOC}"

  hanelly-db:
    image: mysql:5.7
    volumes:
      - ./mysql-data:/var/lib/mysql
    # parametrize password in the clear
    environment:
      MYSQL_ROOT_PASSWORD: ${NAK_MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: hanelly
      MYSQL_USER: hanelly
      MYSQL_PASSWORD: ${NAK_MYSQL_PASSWORD}

  elasticsearch:
    image: elasticsearch:5.2.0
    volumes:
      # docker copies the contents of each host directory over to the container directory and overwrites it
      - ./es-data:/usr/share/elasticsearch/data
      - ./es-logs:/usr/share/elasticsearch/logs
      # the following volume is mapped to a named volume because it contains subdirectories and data which we don't want to overwrite
      #- es-JVM-workingDir:/usr/lib/jvm/java-8-openjdk-amd64/jre
    environment:
      ES_JAVA_OPTS: "${NAK_ES_MEM_ALLOC}"
    # need to disable swap for ES as per: but seems to crash ES https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html
    command: elasticsearch -Enetwork.bind_host=0.0.0.0 -Enetwork.publish_host=elasticsearch -Ecluster.name=elasticsearch -Escript.inline=true -Escript.stored=true -Escript.max_compilations_per_minute=100000
    # ensure data, logs and JVM working directory are mapped externally to container for data persistence and problem troubleshooting post crash

  taskmanager:
    image: nakisa/tools:${NAK_TASKMGR_IMG_TAG}
    volumes:
      - ./tm-logs:/nakisa-queue/logs
    environment:
      nakisa.application.service.url: "http://hanelly:8080/hanelly/app/services/QueueService/"
      nak.authentication.token: "${NAK_AUTH_TOKEN}"

  idoclistener:
    image: nakisa/tools:${NAK_IDOC_IMG_TAG}
    depends_on:
      - hanelly
    volumes:
      - ./idocs-data:/data
      - ./idocs-logs:/idoc-listener/logs
    environment:
      nak.app.url: "http://hanelly:8080/hanelly/app"
      nak.volume.path.idoc: "/data"
      nak.authentication.token: "${NAK_AUTH_TOKEN}"

  backupmanager:
    image: nakisa/tools:${NAK_BACREC_IMG_TAG}
    volumes:
      - ./bnr-data:/nakisa/backup
      - ./bnr-logs:/nakisa-backup/logs
      - ./bnr-storage:/nakisa/storage/fakeStorage
    environment:
      nak.app.name: "hanelly"
      nak.app.image: "${NAK_HANELLY_IMG_TAG}"
      nak.app.service.url: "http://hanelly:8080/hanelly/app/services/BackupRecoveryService/backup"
      nak.authentication.token: "${NAK_AUTH_TOKEN}"
      nak.volume.path.backup: "/nakisa/backup"
      nak.app.storage.external: "/nakisa/storage"
      aws.accesskey: "${NAK_AWS_ACCESS_KEY}"
      aws.secretkey: "${NAK_AWS_SECRET_KEY}"
      aws.bucket: "${NAK_AWS_BUCKET}"
      aws.customer: "${NAK_AWS_CUSTOMER}"
      aws.region: "${NAK_AWS_REGION}"
      aws.installation: "${NAK_AWS_INSALLATION}"
      aws.availabilityzone: "${NAK_AWS_AVL_ZONE}"
      aws.vpcnetwork: "${NAK_AWS_VPC_NETWORK}"
      aws.customernetwork: "${NAK_AWS_CUSTOMER_NETWORK}"
      aws.subnettype: "${NAK_AWS_SUBNET_TYPE}"
      nak.default.backup.schedule.cron: "0 0 0 1/1 * ? *"
      nak.default.backup.sons.count: "7"
      nak.default.backup.fathers.count: "4"
      nak.default.backup.grandfathers.count: "13"
      nak.default.backup.local.storage: "false"

  cadvisor:
    image: google/cadvisor:v0.25.0
    volumes:
      - "/:/rootfs:ro"
      - "/var/run:/var/run"
      - "/sys:/sys:ro"
      - "/var/lib/docker/:/var/lib/docker:ro"

  db-monitor:
    image: prom/mysqld-exporter:v0.10.0
    depends_on:
      - hanelly-db
    environment:
      DATA_SOURCE_NAME: "hanelly:${NAK_MYSQL_PASSWORD}@(hanelly-db:3306)/hanelly"

  prometheus:
    image: prom/prometheus:v1.6.0
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:4.2.0
    volumes:
      - ./grafana-startup:/var/lib/nakisa
      - ./grafana:/var/lib/grafana
    environment:
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s:/grafana"
      GF_SERVER_DOMAIN: "grafana"
    entrypoint: bash /var/lib/nakisa/setup.sh
