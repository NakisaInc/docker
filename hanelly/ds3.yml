version: '3'

# Must declare a named volume which is mapped to Hanelly container directory
# this is because the container directory is not empty and we don't want the host directory to overwrite it.
# named volumes must be removed manually or they will stick around after 'docker stack rm'
volumes:
  hanelly-data:
  # need more here for JVM working dirs for all containers that have them...
  # but need to also understand named volume cleanup very well before we go creating tons of named volumes that stick around

services:
  nginx:
    image: nginx:1.11.5
    # must figure out a way to set memory allocation for NGINX like we do for ES and Hanelly
    depends_on:
      - hanelly
    volumes:
      - ./nginx/:/etc/nginx/conf.d/external/
    ports:
      - "80:80"
      - "443:443"
    # possibly need 504 GW timeout config improvements:
    # https://asdqwe.net/blog/solutions-504-gateway-timeout-nginx/    
    command: /bin/bash -c "cat /etc/nginx/conf.d/external/site.template > /etc/nginx/conf.d/default.conf && nginx -g 'daemon off; error_log /dev/stdout info;'"
  hanelly:
    image: nakisa/hanelly:3.0.0-snapshot
    depends_on:
      - hanelly-db
      - redis
      - elasticsearch
      - backupmanager
      - taskmanager
    volumes:
        - ./agent:/usr/local/tomcat/agent/
        - ./bnr-data:/nakisa/backup
        - ./idocs-data:/nakisa/idocs
        - ./redis-data:/nakisa/redis
        # the following volume would is mapped to a named volume because it contains subdirectories and data which we don't want to overwrite
        - hanelly-data:/usr/local/tomcat/webapps/hanelly
    environment:
        nak.authentication.token: "NakisaInternal"
        nak.queue.url: "http://taskmanager:10000/queue-manager"
        nak.backup.app.url: "http://backupmanager:10001/backup-manager"
        nak.volume.path.idoc: "/nakisa/idocs"
        nak.volume.path.redis: "/nakisa/redis"
        nak.volume.path.backup: "/nakisa/backup"
        JAVA_OPTS: "-Dfile.encoding='UTF-8'"
        CATALINA_OPTS: "-javaagent:/usr/local/tomcat/agent/jmx_prometheus_javaagent-0.8.jar=4000:/usr/local/tomcat/agent/tomcat.yml -Dredis.host=redis -Ddynamic.embedded=false -Ddynamic.host=elasticsearch -Ddynamic.cluster=elasticsearch -Dcluster.standalone=false -Dcluster.discovery.file=WEB-INF/tcp.xml -Djgroups.bind_addr=hanelly -Djava.net.preferIPv4Stack=true -Dfile.encoding='UTF-8' -Xms2g -Xmx2g"
  hanelly-db:
    image: mysql:5.7
    # must figure out a way to set memory allocation for mySQL like we do for ES and Hanelly
    volumes:
        - ./mysql-data:/var/lib/mysql
    # need to get rid of password in the clear!!! 
    environment:
        MYSQL_ROOT_PASSWORD: hanelly
        MYSQL_DATABASE: hanelly
        MYSQL_USER: hanelly
        MYSQL_PASSWORD: hanelly
  redis:
    image: redis:3.2.8
    # must figure out a way to set memory allocation for Redis like we do for ES and Hanelly
    volumes:
      - ./redis-data:/data
      - ./redis-logs:/var/logs/redis
  elasticsearch:
    image: elasticsearch:5.2.0
    volumes:
        # docker copies the contents of each host directory over to the container directory and overwrites it
        - ./es-data:/usr/share/elasticsearch/data
        - ./es-logs:/usr/share/elasticsearch/logs
        # the following volume would is mapped to a named volume because it contains subdirectories and data which we don't want to overwrite
        #- es-JVM-workingDir:/usr/lib/jvm/java-8-openjdk-amd64/jre
    environment:
      ES_JAVA_OPTS: "-Xms2g -Xmx2g"
    # need to disable swap for ES as per: but seems to crash ES https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html
    command: elasticsearch -Enetwork.bind_host=0.0.0.0 -Enetwork.publish_host=elasticsearch -Ecluster.name=elasticsearch -Escript.inline=true -Escript.stored=true -Escript.max_compilations_per_minute=100000
    # ensure data, logs and JVM working directory are mapped externally to container for data persistence and problem troubleshooting post crash
  idoclistener:
    # need a tagged image at CR
    image: nakisa/tools:idoc-listener
    depends_on:
      - hanelly
    ports:
      - "10002:10002"
    volumes:
        - ./idocs-data:/data
        - ./idocs-logs:/idoc-listener/logs
    environment:
        nak.app.url: "http://hanelly:8080/hanelly/app"
        nak.volume.path.idoc: "/data"
        nak.authentication.token: "NakisaInternal"
  backupmanager:
    image: nakisa/tools:backup-management
    ports:
      - "10001:10001"
    volumes:
        - ./bnr-data:/nakisa/backup
        - ./bnr-logs:/nakisa-backup/logs
        - ./bnr-storage:/nakisa/storage/fakeStorage
    environment:
        nak.app.name: "hanelly"
        nak.app.image: "3.0.0-snapshot"
        nak.app.service.url: "http://hanelly:8080/hanelly/app/services/BackupRecoveryService/backup"
        nak.authentication.token: "NakisaInternal"
        nak.volume.path.backup: "/nakisa/backup"
        nak.app.storage.external: "/nakisa/storage"
        aws.accesskey: "change to AWS account access key"
        aws.secretkey: "change to AWS account secret key"
        aws.bucket: "nakisa-dev-br-ca-central-1"
        aws.customer: "testCustomer2"
        aws.region: "ca-central-1"
        aws.installation: "testInstallation2"
        aws.availabilityzone: "nozone"
        aws.vpcnetwork: "novpc"
        aws.customernetwork: "nonetwork"
        aws.subnettype: "nosubnet"
        nak.default.backup.schedule.cron: "0 0 0 1/1 * ? *"
        nak.default.backup.sons.count: "7"
        nak.default.backup.fathers.count: "4"
        nak.default.backup.grandfathers.count: "13"
        nak.default.backup.local.storage: "true"
  taskmanager:
    image: nakisa/tools:task-manager
    ports:
      - "10000:10000"
    volumes:
        - ./tm-logs:/nakisa-queue/logs
    environment:
        nakisa.application.service.url: "http://hanelly:8080/hanelly/app/services/QueueService/"
        nak.authentication.token: "NakisaInternal"
  cadvisor:
    image: google/cadvisor:v0.25.0
    # must figure out a way to set memory allocation for cAdvisor like we do for ES and Hanelly
    volumes:
      - "/:/rootfs:ro"
      - "/var/run:/var/run"
      - "/sys:/sys:ro"
      - "/var/lib/docker/:/var/lib/docker:ro"
  db-monitor:
    image: prom/mysqld-exporter:v0.10.0
    # must figure out a way to set memory allocation for dmMonitor like we do for ES and Hanelly
    depends_on:
      - hanelly-db
    environment:
      DATA_SOURCE_NAME: "hanelly:hanelly@(hanelly-db:3306)/hanelly"
  prometheus:
    image: prom/prometheus:v1.6.0
    # must figure out a way to set memory allocation for Prometheus like we do for ES and Hanelly
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  grafana:
    image: grafana/grafana:4.2.0
    # must figure out a way to set memory allocation for Grafana like we do for ES and Hanelly
    volumes:
      - ./grafana-startup:/var/lib/nakisa
      - ./grafana:/var/lib/grafana
    environment:
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s:/grafana"
      GF_SERVER_DOMAIN: "grafana"
    entrypoint: bash /var/lib/nakisa/setup.sh
      

